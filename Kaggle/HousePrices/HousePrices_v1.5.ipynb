{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path = 'D:/CS/ML/Kaggle/HousePrices/all/'\n",
    "\n",
    "train = pd.read_csv('%s%s' %(path, 'train.csv'))\n",
    "\n",
    "test = pd.read_csv('%s%s' %(path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.umath_tests import inner1d\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除异常点\n",
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
    "train = train.drop(train[(train['OverallQual']<5) & (train['SalePrice']>200000)].index)\n",
    "# 切分点记录\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "# 合并测试集训练集\n",
    "test['SalePrice']= None\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "# 该特征值基本都是同一特征，删除\n",
    "train_test = train_test.drop(['Utilities'], axis=1)\n",
    "#train_test = train_test.drop(['Street'], axis=1)\n",
    "\n",
    "# 用none填补缺失值\n",
    "none_col = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', \n",
    "            'GarageQual', 'GarageFinish', 'GarageCond',\n",
    "            'GarageType', 'BsmtExposure', 'BsmtCond', 'BsmtQual', \n",
    "            'BsmtFinType2', 'BsmtFinType1', 'MasVnrType' ] #'GarageYrBlt',\n",
    "for nnone in none_col:\n",
    "    train_test[nnone].fillna('None', inplace=True)\n",
    "    \n",
    "# 用0填补缺失值\n",
    "zero_col = ['MasVnrArea', 'GarageYrBlt','BsmtFullBath', 'BsmtHalfBath','GarageArea', 'BsmtFinSF2', 'TotalBsmtSF', 'GarageCars', 'BsmtUnfSF', 'BsmtFinSF1']\n",
    "for zzero in zero_col:\n",
    "    train_test[zzero].fillna(0, inplace=True)\n",
    "    \n",
    "# 用众数填补缺失值\n",
    "all_col = [\"MSZoning\", \"Functional\", \"Electrical\", \"KitchenQual\", \"SaleType\",\"Exterior1st\", \"Exterior2nd\"]#, \"Utilities\", \"BsmtFullBath\", \"BsmtHalfBath\",\n",
    "for aall in all_col:\n",
    "    train_test[aall].fillna(train_test[aall].mode()[0], inplace=True)\n",
    "    \n",
    "# 中位数填补\n",
    "#train_test[\"LotAreaCut\"] = pd.qcut(train_test.LotArea,10)\n",
    "#train_test['LotFrontage']=train_test.groupby(['LotAreaCut', 'Neighborhood'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "#train_test['LotFrontage']=train_test.groupby(['LotAreaCut'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "train_test[\"LotFrontage\"] = train_test.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# 删除无用标签和售价\n",
    "#train_test.drop(\"LotAreaCut\",axis=1,inplace=True)\n",
    "train_test.drop(['SalePrice'],axis=1,inplace=True)\n",
    "train_test.drop(['Id'],axis=1,inplace=True)\n",
    "\n",
    "train_test['MSZoning'] = train_test['MSZoning'].fillna(train_test['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test['Total_sqr_footage'] = (train_test['BsmtFinSF1'] + train_test['BsmtFinSF2'] +\n",
    "#                                 train_test['1stFlrSF'] + train_test['2ndFlrSF'])\n",
    "\n",
    "#train_test['Total_Bathrooms'] = (train_test['FullBath'] + (0.5*train_test['HalfBath']) + \n",
    "#                               train_test['BsmtFullBath'] + (0.5*train_test['BsmtHalfBath']))\n",
    "\n",
    "#train_test['Total_porch_sf'] = (train_test['OpenPorchSF'] + train_test['3SsnPorch'] +\n",
    "#                              train_test['EnclosedPorch'] + train_test['ScreenPorch'] +\n",
    "#                             train_test['WoodDeckSF'])\n",
    "\n",
    "\n",
    "#simplified features\n",
    "#train_test['haspool'] = train_test['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "#train_test['has2ndfloor'] = train_test['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "#train_test['hasgarage'] = train_test['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "#train_test['hasbsmt'] = train_test['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "#train_test['hasfireplace'] = train_test['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2916, 78)\n"
     ]
    }
   ],
   "source": [
    "#MSSubClass=The building class\n",
    "train_test['MSSubClass'] = train_test['MSSubClass'].apply(str)\n",
    "\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "train_test['OverallCond'] = train_test['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "train_test['YrSold'] = train_test['YrSold'].astype(str)\n",
    "train_test['MoSold'] = train_test['MoSold'].astype(str)\n",
    "\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold', 'Street') #, 'Street'\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(train_test[c].values)) \n",
    "    train_test[c] = lbl.transform(list(train_test[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(train_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding total sqfootage feature \n",
    "train_test['TotalSF'] = train_test['TotalBsmtSF'] + train_test['1stFlrSF'] + train_test['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>21.935910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>17.685603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>13.262550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>12.082427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>11.370087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <td>4.994554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>4.299698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>4.143683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>4.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>3.944305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Skew\n",
       "MiscVal        21.935910\n",
       "PoolArea       17.685603\n",
       "LotArea        13.262550\n",
       "LowQualFinSF   12.082427\n",
       "3SsnPorch      11.370087\n",
       "LandSlope       4.994554\n",
       "KitchenAbvGr    4.299698\n",
       "BsmtFinSF2      4.143683\n",
       "EnclosedPorch   4.001570\n",
       "ScreenPorch     3.944305"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "numeric_feats = train_test.dtypes[train_test.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = train_test[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59 skewed numerical features to Box Cox transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nX_numeric=train_test.select_dtypes(exclude=[\"object\"])\\nskewness = X_numeric.apply(lambda x: skew(x.dropna))\\nskewness_features = skewness[abs(skewness) >= 0.75].index\\nfrom scipy.special import boxcox1p\\nlam = 0.15\\n#for feat in skewed_features:\\ntrain_test[skewness_features] = boxcox1p(train_test[skewness_features], lam)\\n#train_test.drop([\\'Id\\'],axis=1,inplace=True)\\n'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    train_test[feat] = boxcox1p(train_test[feat], lam)\n",
    "\n",
    "'''\n",
    "X_numeric=train_test.select_dtypes(exclude=[\"object\"])\n",
    "skewness = X_numeric.apply(lambda x: skew(x.dropna))\n",
    "skewness_features = skewness[abs(skewness) >= 0.75].index\n",
    "from scipy.special import boxcox1p\n",
    "lam = 0.15\n",
    "#for feat in skewed_features:\n",
    "train_test[skewness_features] = boxcox1p(train_test[skewness_features], lam)\n",
    "#train_test.drop(['Id'],axis=1,inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2916, 220)\n"
     ]
    }
   ],
   "source": [
    "train_test = pd.get_dummies(train_test)\n",
    "print(train_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train_test[:ntrain]\n",
    "test1 = train_test[ntrain:]\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(train1)\n",
    "train_x_sd1 = scaler.transform(train1)\n",
    "test_x_sd1 = scaler.transform(test1)\n",
    "y_log = np.log1p(train.SalePrice)\n",
    "y_log = y_log.values.reshape(-1,1).ravel()\n",
    "#y_log = train[\"SalePrice\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.24769912, 12.10901644, 12.31717117, ..., 12.49313327,\n",
       "       11.86446927, 11.90159023])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),Ridge(),Lasso(alpha =0.0005, random_state=1),RandomForestRegressor(),GradientBoostingRegressor(),SVR(),LinearSVR(),\n",
    "          ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3),SGDRegressor(max_iter=1000,tol=1e-3),BayesianRidge(),KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n",
    "          ExtraTreesRegressor(),XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.123859, 0.0100\n",
      "Ridge: 0.118158, 0.0093\n",
      "Lasso: 0.111422, 0.0072\n",
      "RF: 0.147984, 0.0041\n",
      "GBR: 0.121597, 0.0065\n",
      "SVR: 0.130214, 0.0095\n",
      "LinSVR: 0.184766, 0.0329\n",
      "Ela: 0.111477, 0.0072\n",
      "SGD: 2594599291651.009277, 210564977386.7416\n",
      "Bay: 0.114065, 0.0076\n",
      "Ker: 0.118019, 0.0090\n",
      "Extra: 0.135636, 0.0081\n",
      "Xgb: 0.115499, 0.0058\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\",\"Xgb\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, train_x_sd1,y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std())) # format为格式化，使输出按照指定样式排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grid():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def grid_get(self,X,y,param_grid):\n",
    "        grid_search = GridSearchCV(self.model,param_grid,cv=5, scoring=\"neg_mean_squared_error\",return_train_score=True)\n",
    "        grid_search.fit(X,y)\n",
    "        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))\n",
    "        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n",
    "        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 13} 0.11405031227872679\n",
      "          params  mean_test_score  std_test_score\n",
      "0  {'alpha': 14}         0.114053        0.001635\n",
      "1  {'alpha': 12}         0.114057        0.001658\n",
      "2  {'alpha': 13}         0.114050        0.001646\n"
     ]
    }
   ],
   "source": [
    "grid(Ridge()).grid_get(train_x_sd1,y_log,{'alpha':[14,12,13]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 200, 'coef0': 2000, 'degree': 2, 'kernel': 'polynomial'} 0.11380099048725204\n",
      "                                              params  mean_test_score  \\\n",
      "0  {'alpha': 200, 'coef0': 500, 'degree': 2, 'ker...         0.115394   \n",
      "1  {'alpha': 200, 'coef0': 1500, 'degree': 2, 'ke...         0.113845   \n",
      "2  {'alpha': 200, 'coef0': 2000, 'degree': 2, 'ke...         0.113801   \n",
      "3  {'alpha': 150, 'coef0': 500, 'degree': 2, 'ker...         0.114798   \n",
      "4  {'alpha': 150, 'coef0': 1500, 'degree': 2, 'ke...         0.113812   \n",
      "5  {'alpha': 150, 'coef0': 2000, 'degree': 2, 'ke...         0.113894   \n",
      "6  {'alpha': 50, 'coef0': 500, 'degree': 2, 'kern...         0.114018   \n",
      "7  {'alpha': 50, 'coef0': 1500, 'degree': 2, 'ker...         0.114876   \n",
      "8  {'alpha': 50, 'coef0': 2000, 'degree': 2, 'ker...         0.115387   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.001549  \n",
      "1        0.001592  \n",
      "2        0.001625  \n",
      "3        0.001546  \n",
      "4        0.001616  \n",
      "5        0.001657  \n",
      "6        0.001581  \n",
      "7        0.001733  \n",
      "8        0.001781  \n"
     ]
    }
   ],
   "source": [
    "param_grid ={'alpha':[200,150,50], 'kernel':[\"polynomial\"], 'degree':[2],'coef0':[500,1500,2000]}\n",
    "grid(KernelRidge()).grid_get(train_x_sd1,y_log,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'n_estimators': 2000} 0.117171798221295\n",
      "                                          params  mean_test_score  \\\n",
      "0  {'learning_rate': 0.05, 'n_estimators': 2000}         0.117172   \n",
      "1  {'learning_rate': 0.05, 'n_estimators': 2500}         0.117190   \n",
      "2  {'learning_rate': 0.05, 'n_estimators': 3000}         0.117247   \n",
      "3   {'learning_rate': 0.1, 'n_estimators': 2000}         0.119127   \n",
      "4   {'learning_rate': 0.1, 'n_estimators': 2500}         0.119161   \n",
      "5   {'learning_rate': 0.1, 'n_estimators': 3000}         0.119152   \n",
      "6  {'learning_rate': 0.01, 'n_estimators': 2000}         0.118538   \n",
      "7  {'learning_rate': 0.01, 'n_estimators': 2500}         0.117851   \n",
      "8  {'learning_rate': 0.01, 'n_estimators': 3000}         0.117491   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.001733  \n",
      "1        0.001739  \n",
      "2        0.001761  \n",
      "3        0.002342  \n",
      "4        0.002321  \n",
      "5        0.002325  \n",
      "6        0.001746  \n",
      "7        0.001827  \n",
      "8        0.001878  \n"
     ]
    }
   ],
   "source": [
    "param ={'n_estimators':[2000,2500,3000], 'learning_rate':[0.05,0.1,0.01]}\n",
    "grid(XGBRegressor()).grid_get(train_x_sd1,y_log,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso= Lasso(alpha =0.0005, random_state=1)\n",
    "ela = ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\n",
    "\n",
    "bay = BayesianRidge()\n",
    "#gbr = GradientBoostingRegressor(alpha = 0.5, learning_rate = 0.1, n_estimators = 180)\n",
    "ker = KernelRidge(alpha=100, kernel='polynomial', degree=2, coef0=1000)\n",
    "xgbt = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# votiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 0.3\n",
    "w2 = 0.3\n",
    "w3 = 0.2\n",
    "w4 = 0.05\n",
    "w5 = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_avg = AverageWeight(mod = [lasso,ela,bay,ker,xgbt],weight=[w1,w2,w3,w4,w5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11038968871668328"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv(weight_avg,train_x_sd1,y_log).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11038968871668328"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_avg2  = AverageWeight(mod = [lasso,ela],weight=[0.5,0.5])\n",
    "rmse_cv(weight_avg,train_x_sd1,y_log).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_avg.fit(train_x_sd1,y_log)\n",
    "pred = np.exp(weight_avg.predict(test_x_sd1))\n",
    "result_vot=pd.DataFrame({'Id':test.Id, 'SalePrice':pred})\n",
    "result_vot.to_csv(\"D:/CS/ML/Kaggle/HousePrices/v1.0/submission_vote1.52.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = StackingAveragedModels(base_models=[lasso,ela,bay,ker,xgbt],meta_model=lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11013085138178921"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv(stack_model,train_x_sd1,y_log).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model.fit(train_x_sd1,y_log)\n",
    "stacked_pred = np.expm1(stack_model.predict(test_x_sd1))\n",
    "result_vot=pd.DataFrame({'Id':test.Id, 'SalePrice':stacked_pred})\n",
    "result_vot.to_csv(\"D:/CS/ML/Kaggle/HousePrices/v1.0/submission_stacking1.52.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(train_x_sd1,y_log)\n",
    "pred_lasso = np.expm1(lasso.predict(test_x_sd1))\n",
    "ela.fit(train_x_sd1,y_log)\n",
    "pred_ela = np.expm1(ela.predict(test_x_sd1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mix = stacked_pred *0.7+0.15*pred_ela+0.15*pred_lasso\n",
    "result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred_mix})\n",
    "result.to_csv(\"D:/CS/ML/Kaggle/HousePrices/v1.0/submission_mix1.2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
