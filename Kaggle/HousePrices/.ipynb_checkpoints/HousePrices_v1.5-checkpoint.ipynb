{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path = 'D:/CS/ML/Kaggle/HousePrices/all/'\n",
    "\n",
    "train = pd.read_csv('%s%s' %(path, 'train.csv'))\n",
    "\n",
    "test = pd.read_csv('%s%s' %(path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.core.umath_tests import inner1d\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除异常点\n",
    "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
    "\n",
    "# 切分点记录\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "# 合并测试集训练集\n",
    "test['SalePrice']= None\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "# 该特征值基本都是同一特征，删除\n",
    "train_test = train_test.drop(['Utilities'], axis=1)\n",
    "\n",
    "# 用none填补缺失值\n",
    "none_col = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', \n",
    "            'GarageQual', 'GarageFinish', 'GarageCond',\n",
    "            'GarageType', 'BsmtExposure', 'BsmtCond', 'BsmtQual', \n",
    "            'BsmtFinType2', 'BsmtFinType1', 'MasVnrType' ] #'GarageYrBlt',\n",
    "for nnone in none_col:\n",
    "    train_test[nnone].fillna('None', inplace=True)\n",
    "    \n",
    "# 用0填补缺失值\n",
    "zero_col = ['MasVnrArea', 'GarageYrBlt','BsmtFullBath', 'BsmtHalfBath','GarageArea', 'BsmtFinSF2', 'TotalBsmtSF', 'GarageCars', 'BsmtUnfSF', 'BsmtFinSF1']\n",
    "for zzero in zero_col:\n",
    "    train_test[zzero].fillna(0, inplace=True)\n",
    "    \n",
    "# 用众数填补缺失值\n",
    "all_col = [\"MSZoning\", \"Functional\", \"Electrical\", \"KitchenQual\", \"SaleType\",\"Exterior1st\", \"Exterior2nd\"]#, \"Utilities\", \"BsmtFullBath\", \"BsmtHalfBath\",\n",
    "for aall in all_col:\n",
    "    train_test[aall].fillna(train_test[aall].mode()[0], inplace=True)\n",
    "    \n",
    "# 中位数填补\n",
    "#train_test[\"LotAreaCut\"] = pd.qcut(train_test.LotArea,10)\n",
    "#train_test['LotFrontage']=train_test.groupby(['LotAreaCut', 'Neighborhood'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "#train_test['LotFrontage']=train_test.groupby(['LotAreaCut'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "train_test[\"LotFrontage\"] = train_test.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# 删除无用标签和售价\n",
    "#train_test.drop(\"LotAreaCut\",axis=1,inplace=True)\n",
    "train_test.drop(['SalePrice'],axis=1,inplace=True)\n",
    "train_test.drop(['Id'],axis=1,inplace=True)\n",
    "\n",
    "train_test['MSZoning'] = train_test['MSZoning'].fillna(train_test['MSZoning'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (2917, 78)\n"
     ]
    }
   ],
   "source": [
    "#MSSubClass=The building class\n",
    "train_test['MSSubClass'] = train_test['MSSubClass'].apply(str)\n",
    "\n",
    "\n",
    "#Changing OverallCond into a categorical variable\n",
    "train_test['OverallCond'] = train_test['OverallCond'].astype(str)\n",
    "\n",
    "\n",
    "#Year and month sold are transformed into categorical features.\n",
    "train_test['YrSold'] = train_test['YrSold'].astype(str)\n",
    "train_test['MoSold'] = train_test['MoSold'].astype(str)\n",
    "\n",
    "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "# process columns, apply LabelEncoder to categorical features\n",
    "for c in cols:\n",
    "    lbl = LabelEncoder() \n",
    "    lbl.fit(list(train_test[c].values)) \n",
    "    train_test[c] = lbl.transform(list(train_test[c].values))\n",
    "\n",
    "# shape        \n",
    "print('Shape all_data: {}'.format(train_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding total sqfootage feature \n",
    "train_test['TotalSF'] = train_test['TotalBsmtSF'] + train_test['1stFlrSF'] + train_test['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>21.939672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>17.688664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>13.109495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>12.084539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>11.372080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LandSlope</th>\n",
       "      <td>4.973254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>4.300550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>4.144503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>4.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>3.945101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Skew\n",
       "MiscVal        21.939672\n",
       "PoolArea       17.688664\n",
       "LotArea        13.109495\n",
       "LowQualFinSF   12.084539\n",
       "3SsnPorch      11.372080\n",
       "LandSlope       4.973254\n",
       "KitchenAbvGr    4.300550\n",
       "BsmtFinSF2      4.144503\n",
       "EnclosedPorch   4.002344\n",
       "ScreenPorch     3.945101"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "numeric_feats = train_test.dtypes[train_test.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = train_test[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59 skewed numerical features to Box Cox transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nX_numeric=train_test.select_dtypes(exclude=[\"object\"])\\nskewness = X_numeric.apply(lambda x: skew(x.dropna))\\nskewness_features = skewness[abs(skewness) >= 0.75].index\\nfrom scipy.special import boxcox1p\\nlam = 0.15\\n#for feat in skewed_features:\\ntrain_test[skewness_features] = boxcox1p(train_test[skewness_features], lam)\\n#train_test.drop([\\'Id\\'],axis=1,inplace=True)\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    train_test[feat] = boxcox1p(train_test[feat], lam)\n",
    "\n",
    "'''\n",
    "X_numeric=train_test.select_dtypes(exclude=[\"object\"])\n",
    "skewness = X_numeric.apply(lambda x: skew(x.dropna))\n",
    "skewness_features = skewness[abs(skewness) >= 0.75].index\n",
    "from scipy.special import boxcox1p\n",
    "lam = 0.15\n",
    "#for feat in skewed_features:\n",
    "train_test[skewness_features] = boxcox1p(train_test[skewness_features], lam)\n",
    "#train_test.drop(['Id'],axis=1,inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2917, 220)\n"
     ]
    }
   ],
   "source": [
    "train_test = pd.get_dummies(train_test)\n",
    "print(train_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train_test[:ntrain]\n",
    "test1 = train_test[ntrain:]\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(train1)\n",
    "train_x_sd1 = scaler.transform(train1)\n",
    "test_x_sd1 = scaler.transform(test1)\n",
    "y_log = np.log1p(train.SalePrice)\n",
    "y_log = y_log.values.reshape(-1,1).ravel()\n",
    "#y_log = train[\"SalePrice\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.24769912, 12.10901644, 12.31717117, ..., 12.49313327,\n",
       "       11.86446927, 11.90159023])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(),Ridge(),Lasso(alpha =0.0005, random_state=1),RandomForestRegressor(),GradientBoostingRegressor(),SVR(),LinearSVR(),\n",
    "          ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3),SGDRegressor(max_iter=1000,tol=1e-3),BayesianRidge(),KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n",
    "          ExtraTreesRegressor(),XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.123794, 0.0109\n",
      "Ridge: 0.118211, 0.0098\n",
      "Lasso: 0.111549, 0.0074\n",
      "RF: 0.146921, 0.0052\n",
      "GBR: 0.121499, 0.0063\n",
      "SVR: 0.130264, 0.0095\n",
      "LinSVR: 0.161140, 0.0185\n",
      "Ela: 0.111565, 0.0074\n",
      "SGD: 2617527930101.291504, 376262205831.4435\n",
      "Bay: 0.114207, 0.0079\n",
      "Ker: 0.118147, 0.0091\n",
      "Extra: 0.135089, 0.0098\n",
      "Xgb: 0.116494, 0.0058\n"
     ]
    }
   ],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\",\"Xgb\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, train_x_sd1,y_log)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std())) # format为格式化，使输出按照指定样式排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso= Lasso(alpha =0.0005, random_state=1)\n",
    "ela = ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\n",
    "\n",
    "bay = BayesianRidge()\n",
    "#gbr = GradientBoostingRegressor(alpha = 0.5, learning_rate = 0.1, n_estimators = 180)\n",
    "ker = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "xgbt = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# votiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 0.3\n",
    "w2 = 0.3\n",
    "w3 = 0.2\n",
    "w4 = 0.05\n",
    "w5 = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_avg = AverageWeight(mod = [lasso,ela,bay,ker,xgbt],weight=[w1,w2,w3,w4,w5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11025052578129857"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv(weight_avg,train_x_sd1,y_log).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11025052578129857"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_avg2  = AverageWeight(mod = [lasso,ela],weight=[0.5,0.5])\n",
    "rmse_cv(weight_avg,train_x_sd1,y_log).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_avg.fit(train_x_sd1,y_log)\n",
    "pred = np.exp(weight_avg.predict(test_x_sd1))\n",
    "result_vot=pd.DataFrame({'Id':test.Id, 'SalePrice':pred})\n",
    "result_vot.to_csv(\"D:/CS/ML/Kaggle/HousePrices/v1.0/submission_vote1.51.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = StackingAveragedModels(base_models=[lasso,ela,bay,ker,xgbt],meta_model=lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10993316740785986"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_cv(stack_model,train_x_sd1,y_log).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model.fit(train_x_sd1,y_log)\n",
    "stacked_pred = np.expm1(stack_model.predict(test_x_sd1))\n",
    "result_vot=pd.DataFrame({'Id':test.Id, 'SalePrice':stacked_pred})\n",
    "result_vot.to_csv(\"D:/CS/ML/Kaggle/HousePrices/v1.0/submission_stacking1.51.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(train_x_sd1,y_log)\n",
    "pred_lasso = np.expm1(lasso.predict(test_x_sd1))\n",
    "ela.fit(train_x_sd1,y_log)\n",
    "pred_ela = np.expm1(ela.predict(test_x_sd1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mix = stacked_pred *0.7+0.15*pred_ela+0.15*pred_lasso\n",
    "result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred_mix})\n",
    "result.to_csv(\"D:/CS/ML/Kaggle/HousePrices/v1.0/submission_mix1.1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
