# 2.支持向量机
支持向量机 (SVMs) 可用于以下监督学习算法分类,回归和异常检测.
支持向量机的优势在于:
* 在高维空间中非常高效.
* 即使在数据维度比样本数量大的情况下仍然有效.

缺点在于:如果特征数量比样本数量大得多,在选择核函数时要避免过拟合。

对于支持向量机的整个推导过程如下：
线性分类器->线性可分SVM->线性不可分SVM->对偶SVM->非线性模型->最优解

## 2.1.最优化问题
最优化问题可以用拉格朗日乘法求解，对于既有等式约束又有不等式约束的问题，也有类似的条件定义函数的最优解-这就是KKT条件。

### 2.1.1.拉格朗日乘子
对于如下优化问题：

$$
\left\{ \begin{array}{c}
	\min f\left( X \right)\\
	g_i\left( X \right) \leqslant \text{0\ }i=\text{1,...,}q\\
	h_i\left( X \right) =\text{0\ }i=\text{1,...,}p\\
\end{array} \right. 
$$

首先构造拉格朗日乘子函数：

$$
L\left( X,\lambda ,\mu \right) =f\left( X \right) +\sum_{j=1}^p{\lambda _j}h_j\left( X \right) +\sum_{k=1}^q{\mu _kg_k\left( X \right)}
$$

其中：$\lambda _j,\mu _k$称为拉格朗日乘子，最优解为$X ^*$
必须满足的条件如下：

$$
\begin{cases}
	h_j\left( X^* \right) =0\\
	g_k\left( X^* \right) \leqslant 0\\
	\nabla _XL\left( X^* \right) =0\\
	\lambda _j\ne 0\\
	\mu _k\geqslant 0\\
	\mu _kg_k\left( X^* \right) =0\\
\end{cases}
$$

### 2.1.2.拉格朗日对偶
对偶是最求解优化问题的一种手段，它将一个优化问题转化为另外一个更容易求解的问题.

对于如下优化问题：

$$
\left\{ \begin{array}{c}
	\min f\left( X \right)\\
	g_i\left( X \right) \leqslant \text{0\ }i=\text{1,...,}m\\
	h_i\left( X \right) =\text{0\ }i=\text{1,...,}p\\
\end{array} \right. 
$$

仿照拉格朗日乘法构造如下广义拉格朗日函数：

$$
L\left( X,\lambda ,\nu \right) =f\left( X \right) +\sum_{i=1}^m{\lambda _i}g_i\left( X \right) +\sum_{i=1}^p{\nu _ih_i\left( X \right)}
$$

同样称$\lambda _i,\nu _i$为拉格朗日乘子。

变量$\lambda _i$必须满足$\lambda _i\geqslant 0$

接下来将上面问题转化成所谓的原问题形式，其最优解为：

$$
p^*=\min _X\max _{\lambda ,\nu ,\lambda _i\geqslant 0}L\left( X,\lambda ,v \right) =\min _X\theta _P\left( X \right) 
$$
